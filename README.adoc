= NexaServer

image:https://img.shields.io/badge/vert.x-4.5.7-purple.svg[link="https://vertx.io"]

If you just need a backend for collecting data, the project in the python folder might be a more convenient choice.

https://github.com/LLM-Red-Team/kimi-free-api
Deploy kimi service through docker.

This application was generated using http://start.vertx.io

== Configuration

Put your openai api key into the config. The file is at src/main/resources/config.yml.
```yml
openai:
    apiKey: YOUR_KEY
    # If you need a proxy to access openai's apis
    # proxy: http://127.0.0.1:7890

kimi:
    apiKey: YOUR_KEY
    server: http://127.0.0.1:8000/v1/
bas:
    host:
    port:
```

== Building

To launch your tests:
```
./gradlew clean test
```

To package your application:
```
./gradlew clean assemble
```

To run your application:
```
./gradlew clean run
```
== Deployment
Copy the following files to the deployment directory, final directory structure:

  ├── docker-compose.yml
  └── target
     ├── config.yml
     └── nuixserver-1.0.0-SNAPSHOT-fat.jar

run command:
```
docker-compose up -d
```
== Help

* https://vertx.io/docs/[Vert.x Documentation]
* https://stackoverflow.com/questions/tagged/vert.x?sort=newest&pageSize=15[Vert.x Stack Overflow]
* https://groups.google.com/forum/?fromgroups#!forum/vertx[Vert.x User Group]
* https://discord.gg/6ry7aqPWXy[Vert.x Discord]
* https://gitter.im/eclipse-vertx/vertx-users[Vert.x Gitter]


